# amazon_mobiles_scraper_with_discount.py
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time
import csv
import re

PRICE_RE = re.compile(r"[\d,]+")

def parse_amount(text):
    """Convert â‚¹ 1,04,999.00 -> 104999 as int"""
    if not text:
        return None
    m = PRICE_RE.search(text)
    if not m:
        return None
    try:
        return int(m.group(0).replace(",", ""))
    except:
        return None

def scrape_amazon(query, start_page=1, end_page=20, output_csv="amazon_results_mobilephones_with_discount.csv"):
    options = Options()
    options.add_argument("--log-level=3")
    driver = webdriver.Chrome(options=options)
    wait = WebDriverWait(driver, 12)

    driver.get("https://www.amazon.in")
    search_box = wait.until(EC.presence_of_element_located((By.ID, "twotabsearchtextbox")))
    search_box.send_keys(query)
    search_box.send_keys(Keys.RETURN)
    time.sleep(3)

    results = []
    current_page = 1

    # skip until start_page
    while current_page < start_page:
        try:
            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "a.s-pagination-next")))
            driver.execute_script("arguments[0].click();", next_button)
            current_page += 1
            time.sleep(4)
        except:
            print(f"[INFO] Could not reach page {start_page}, stopping.")
            driver.quit()
            return

    # scrape pages
    while current_page <= end_page:
        products = driver.find_elements(By.XPATH, '//div[@data-component-type="s-search-result"]')
        print(f"[PAGE {current_page}] Found {len(products)} products")

        for p in products:
            try:
                title = p.find_element(By.TAG_NAME, "h2").text.strip()
                link = p.find_element(By.TAG_NAME, "a").get_attribute("href")

                # âœ… displayed price from a-offscreen (most reliable)
                try:
                    price_text = p.find_element(By.CSS_SELECTOR, "span.a-price > span.a-offscreen").text
                except:
                    price_text = None
                discounted_price = parse_amount(price_text)

                # âœ… MRP (crossed-out price)
                try:
                    mrp_text = p.find_element(By.CSS_SELECTOR, "span.a-text-price > span.a-offscreen").text
                except:
                    mrp_text = None
                mrp = parse_amount(mrp_text)

                # âœ… discount percentage
                discount_pct = None
                if mrp and discounted_price:
                    discount_pct = round(((mrp - discounted_price) / mrp) * 100, 2)

                results.append({
                    "title": title,
                    "discounted_price": discounted_price if discounted_price else "",
                    "mrp": mrp if mrp else "",
                    "discount_pct": discount_pct if discount_pct else "",
                    "link": link
                })
            except:
                continue

        # next page
        try:
            next_button = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, "a.s-pagination-next")))
            driver.execute_script("arguments[0].click();", next_button)
            current_page += 1
            print("[INFO] Sleeping 6s before next page...")
            time.sleep(6)
        except:
            print("[INFO] No more pages found, stopping.")
            break

    driver.quit()

    # âœ… write to new CSV
    keys = ["title", "discounted_price", "mrp", "discount_pct", "link"]
    with open(output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=keys)
        writer.writeheader()
        writer.writerows(results)

    print(f"âœ… Scraped {len(results)} results across pages {start_page}â€“{current_page-1}")
    print(f"ðŸ’¾ Data saved to {output_csv}")


if __name__ == "__main__":
    scrape_amazon("mobile", start_page=1, end_page=20, output_csv="amazon_results_mobilephones_with_discount.csv")
